{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "- [mne.io.RawArray.plot](https://mne.tools/stable/generated/mne.io.RawArray.html#mne.io.RawArray.plot)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Test 1:\n",
    "\n",
    "```python\n",
    "window_sizes = [2.0]\n",
    "overlaps = [0.1]\n",
    "accuracy ~90%\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'test' from 'PhysioGoDSP' (c:\\Users\\by_he\\Documents\\code\\mci-simple-emg-endless\\physiogo\\PhysioGoDSP.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\by_he\\Documents\\code\\mci-simple-emg-endless\\physiogo\\PhyisoLearn.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/by_he/Documents/code/mci-simple-emg-endless/physiogo/PhyisoLearn.ipynb#ch0000001?line=11'>12</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcopy\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/by_he/Documents/code/mci-simple-emg-endless/physiogo/PhyisoLearn.ipynb#ch0000001?line=12'>13</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjoblib\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/by_he/Documents/code/mci-simple-emg-endless/physiogo/PhyisoLearn.ipynb#ch0000001?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPhysioGoDSP\u001b[39;00m \u001b[39mimport\u001b[39;00m test\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/by_he/Documents/code/mci-simple-emg-endless/physiogo/PhyisoLearn.ipynb#ch0000001?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m \u001b[39mimport\u001b[39;00m signal\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/by_he/Documents/code/mci-simple-emg-endless/physiogo/PhyisoLearn.ipynb#ch0000001?line=17'>18</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mPhysioLearn\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'test' from 'PhysioGoDSP' (c:\\Users\\by_he\\Documents\\code\\mci-simple-emg-endless\\physiogo\\PhysioGoDSP.py)"
     ]
    }
   ],
   "source": [
    "from brainflow.data_filter import DataFilter, FilterTypes, AggOperations\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import model_selection\n",
    "import copy\n",
    "import joblib\n",
    "from PhysioGoDSP import test\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "class PhysioLearn:\n",
    "    def __init__(self, sessionTitle, num_channels, channel_type, eventMapping=None, eventFile=None, ):\n",
    "        print()\n",
    "        self.currentFileDf = []\n",
    "        self.currentFile = None\n",
    "        self.channels = num_channels\n",
    "        self.channelTypes = [channel_type] * num_channels\n",
    "        self.channelNames = [str(n) for n in range(num_channels)]\n",
    "        self.sfreq = 200\n",
    "        self.mneFactor = 1000000 # account for unit conversion if necessary\n",
    "        self.markerChannel = 14\n",
    "        self.eventMapping = eventMapping\n",
    "        \n",
    "        # Check if this is the best approach\n",
    "        if eventFile != None:\n",
    "            self.events = mne.read_events(eventFile)\n",
    "        else:\n",
    "            self.events = []\n",
    "            \n",
    "        self.date = datetime.now().strftime(\"%H_%M_%S\")\n",
    "        self.eventsEmbeded = []\n",
    "        self.raw = None\n",
    "        self.dataset = []\n",
    "        self.info = mne.create_info(\n",
    "            ch_names=self.channelNames, sfreq=self.sfreq, ch_types=self.channelTypes)\n",
    "        print(\"Init Success\")\n",
    "\n",
    "    def createEvents(self, filePath):\n",
    "        i = 0\n",
    "        array = []\n",
    "        for sample in self.currentFileDf[self.markerChannel]:\n",
    "            i = i + 1\n",
    "            if sample != 0.0:\n",
    "                array.append([i, 0, int(sample)])\n",
    "        self.eventsEmbeded = np.array(array, dtype=int)\n",
    "        df = pd.DataFrame(data=self.eventsEmbeded).to_csv(filePath, sep=\" \", index=None, header=None)\n",
    "\n",
    "        \n",
    "\n",
    "    def readFile(self, location):\n",
    "        self.currentFile = DataFilter.read_file(location)\n",
    "        self.currentFileDf = pd.DataFrame(np.transpose(self.currentFile))\n",
    "        res = self.currentFile[1:2] / self.mneFactor # only accounts for 1 channel currently\n",
    "        self.raw = mne.io.RawArray(res, self.info)\n",
    "        \n",
    "\n",
    "    def getDataDuration(self):\n",
    "        #seconds\n",
    "        return len(self.currentFile[0]) / self.sfreq\n",
    "         \n",
    "    def createPlots(self): # what is this doing? \n",
    "        duration = round(self.getDataDuration() - 2)\n",
    "        window_size = duration / 4\n",
    "        if len(self.eventsEmbeded) == 0:\n",
    "            events = self.events\n",
    "        else:\n",
    "            events = self.eventsEmbeded\n",
    "        for i in range(4):\n",
    "            start = i * window_size\n",
    "            self.raw.plot(events=events, start=start, duration=window_size,\n",
    "                 event_id=self.eventMapping)\n",
    "            \n",
    "    def getEvents(self):\n",
    "        if len(self.eventsEmbeded) == 0:\n",
    "            events = self.events\n",
    "        else:\n",
    "            events = self.eventsEmbeded\n",
    "        \n",
    "        return events\n",
    "    \n",
    "    def getWindowBandPower(self, start, duration):\n",
    "        epoch, times = self.getEpoch(start, duration)\n",
    "        [avgs, stddevs] = DataFilter.get_avg_band_powers(epoch, [0], self.sfreq, True)\n",
    "        print(avgs)\n",
    "        return avgs\n",
    "    \n",
    "\n",
    "    def getSignalEnvelope(self, signal):\n",
    "        y = self.rectify(signal)\n",
    "        print(y)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def plotEvents(self, eventDuration):\n",
    "        events = self.getEvents()\n",
    "        e_map = {100: 'Rest', 99: 'Lift', 98: 'Squeeze' }\n",
    "        for event in events:\n",
    "            data, times = self.getEpoch(int(event[0] / self.sfreq), eventDuration)\n",
    "            fig, ax = plt.subplots(figsize=(4.5, 3))\n",
    "            title = e_map[event[2]]\n",
    "            plt.title(title)\n",
    "            ax.plot(times, data[0] * self.mneFactor)\n",
    "            #plt.savefig('raw.png')\n",
    "            \n",
    "    def plot(self, title, data, times):\n",
    "        fig, ax = plt.subplots(figsize=(4.5, 3))\n",
    "        plt.title(title)\n",
    "        ax.plot(times, data * self.mneFactor)\n",
    "        \n",
    "    def plotBasic(self, title, data, times):\n",
    "        fig, ax = plt.subplots(figsize=(4.5, 3))\n",
    "        plt.title(title)\n",
    "        ax.plot(times, data)\n",
    "        \n",
    "            \n",
    "    def featureExtraction(self, epoch_size, window_sizes, overlaps):\n",
    "        events = self.getEvents()\n",
    "        e_map = {100: 'Rest', 99: 'Lift', 98: 'Squeeze' }\n",
    "        window_sizes = window_sizes\n",
    "        channels = [0]\n",
    "        overlaps = overlaps\n",
    "        dataset_x = list()\n",
    "        dataset_y = list()\n",
    "        epochSize = epoch_size\n",
    "        \n",
    "        \n",
    "        for event in events:\n",
    "            for num, window_size in enumerate(window_sizes):\n",
    "                    data, times = self.getEpoch(int(event[0] / self.sfreq), epochSize)\n",
    "                    cur_pos = 0\n",
    "                    #print(data.shape[1])\n",
    "                    while cur_pos + int(window_size * self.sfreq) < data.shape[1]:\n",
    "                        _class = event[2] # last column of event file\n",
    "                        data_in_window = data[:, cur_pos:cur_pos + int(window_size * self.sfreq)]\n",
    "                        times_in_window = times[cur_pos:cur_pos + int(window_size * self.sfreq)]\n",
    "                        #print(data.shape, times.shape)\n",
    "                        #plotTitle = f'{cur_pos}_{_class}_window({window_size})'\n",
    "                        #dataCopy = copy.deepcopy(data_in_window[0])\n",
    "                        #DataFilter.perform_lowpass(data_in_window[0], self.sfreq, 30.0, 1,\n",
    "                        #          FilterTypes.BUTTERWORTH.value, 1)\n",
    "                        #self.plot(plotTitle, data_in_window[0], times_in_window)\n",
    "                        #self.plot(plotTitle+\"filtered\", dataCopy, times_in_window)\n",
    "                        \n",
    "                        # returns 2d array with delta - gamma (bands[0]) \n",
    "                        bands = DataFilter.get_avg_band_powers(data_in_window, channels, self.sfreq, True)\n",
    "                        feature_vector = bands[0]\n",
    "                        if (event[2] != 99):\n",
    "                            dataset_x.append(feature_vector)\n",
    "                            dataset_y.append(e_map[_class])\n",
    "                        \n",
    "                        # review overlap to make it more intuitive....\n",
    "                        cur_pos = cur_pos + int(window_size * overlaps[num] * self.sfreq)\n",
    "        self.dataset = [dataset_x, dataset_y]\n",
    "        return self.dataset\n",
    "                 \n",
    "    def getEpoch(self, start, eventDuration):\n",
    "        start = start * self.sfreq\n",
    "        duration = eventDuration * self.sfreq\n",
    "        stop = start + duration\n",
    "        data, times = self.raw.get_data(return_times=True, start=start, stop=stop)\n",
    "        return data, times\n",
    "    \n",
    "    def saveObject(self, model, filename): \n",
    "        joblib.dump(model, filename)\n",
    "        \n",
    "    def loadObject(self, fileName):\n",
    "        model = joblib.load(fileName)\n",
    "        return model\n",
    "    \n",
    "    def testLocalModel(self, modelFileName, dataset, test_size=0.33, random_state=1):\n",
    "        X_train, X_test, Y_train, Y_test = model_selection.train_test_split(dataset[0], dataset[1], test_size=test_size, random_state=random_state)\n",
    "        model = self.loadModel(modelFileName)\n",
    "        score = model.score(X_test, Y_test)\n",
    "        x = self.dataset[0]\n",
    "        predicted = model.predict(x)\n",
    "        return score\n",
    "        \n",
    "\n",
    "    def start(self, fileName):\n",
    "        self.readFile(fileName)\n",
    "        #self.createEvents()\n",
    "        #self.createPlots() \n",
    "        #self.plotEvents(4)\n",
    "        #data, times = self.getEpoch(0, 10)\n",
    "        #self.getWindowBandPower(0, 5)\n",
    "        \n",
    "        # Get Dataset\n",
    "        #self.dataset = self.prepareData([2.0], [0.1]) # get dataset\n",
    "        \n",
    "        # Train Model\n",
    "        #self.train_knn(self.dataset, 1)\n",
    "        #self.train_lda(self.dataset)\n",
    "        #self.train_regression(self.dataset)\n",
    "        \n",
    "        # Test model\n",
    "        #score = self.testLocalModel(\"models/lda-emg-lift.pkl\", self.dataset)\n",
    "        \n",
    "        #self.saveObject(self.dataset, \"models/squeeze-emg-x-y.dataset\")\n",
    "        \n",
    "        # Load Model\n",
    "        #data = self.loadObject(\"models/lift-emg-x-y.dataset\")\n",
    "     \n",
    "    \n",
    "    def rectify(self, signal):\n",
    "        y = [abs(x) for x in signal]\n",
    "        return y\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    ''' Training '''\n",
    "    def train_knn(self, data, neighbors):\n",
    "        print('#### KNN ####')\n",
    "        model = KNeighborsClassifier(n_neighbors=neighbors)\n",
    "        scores = cross_val_score(model, data[0], data[1], cv=5, scoring='f1_macro', n_jobs=8)\n",
    "        print('f1 macro %s' % str(scores.mean()))\n",
    "        scores = cross_val_score(model, data[0], data[1], cv=5, scoring='precision_macro', n_jobs=8)\n",
    "        print('precision macro %s' % str(scores.mean()))\n",
    "        scores = cross_val_score(model, data[0], data[1], cv=5, scoring='recall_macro', n_jobs=8)\n",
    "        print('recall macro %s' % str(scores.mean()))\n",
    "        return model\n",
    "        \n",
    "    def train_regression(self, data):\n",
    "        print('#### Logistic Regression ####')\n",
    "        model = LogisticRegression(class_weight='balanced', solver='liblinear',\n",
    "                               max_iter=4000, penalty='l2', random_state=1)\n",
    "        scores = cross_val_score(model, data[0], data[1], cv=5, scoring='f1_macro', n_jobs=8)\n",
    "        print('f1 macro %s' % str(scores.mean()))\n",
    "        scores = cross_val_score(model, data[0], data[1], cv=5, scoring='precision_macro', n_jobs=8)\n",
    "        print('precision macro %s' % str(scores.mean()))\n",
    "        scores = cross_val_score(model, data[0], data[1], cv=5, scoring='recall_macro', n_jobs=8)\n",
    "        print('recall macro %s' % str(scores.mean()))\n",
    "        \n",
    "    \n",
    "    def train_lda(self, data):\n",
    "        model = LinearDiscriminantAnalysis()\n",
    "        print('#### Linear Discriminant Analysis ####')\n",
    "        scores = cross_val_score(model, data[0], data[1], cv=5, scoring='f1_macro', n_jobs=8)\n",
    "        print('f1 macro %s' % str(scores.mean()))\n",
    "        scores = cross_val_score(model, data[0], data[1], cv=5, scoring='precision_macro', n_jobs=8)\n",
    "        print('precision macro %s' % str(scores.mean()))\n",
    "        scores = cross_val_score(model, data[0], data[1], cv=5, scoring='recall_macro', n_jobs=8)\n",
    "        print('recall macro %s' % str(scores.mean()))\n",
    "        model.fit(data[0], data[1])\n",
    "        #self.saveObject(model, \"models/lda-emg-lift.pkl\")\n",
    "        \n",
    "        \n",
    "def main():  \n",
    "    event_mapping = {'Rest': 100, 'Lift': 99, 'Squeeze': 98}\n",
    "    #learn = PhysioLearn(1, \"emg\", event_mapping, \"data/events-gen-cleaned-eve.txt\")\n",
    "    learn = PhysioLearn(\"Crawford_EMG_Model\", 1, \"emg\", event_mapping)\n",
    "    learn.readFile(\"data/crawford_EMG_Test.csv\")\n",
    "    learn.createEvents(\"data/crawford_events2.txt\")\n",
    "    #learn.plotEvents(2)\n",
    "    dataset = learn.featureExtraction(4, [2.0], [0.4])\n",
    "    print(learn.dataset)\n",
    "    \n",
    "    # Train Model\n",
    "    #print(dataset[0])\n",
    "    #learn.train_knn(dataset, 2)\n",
    "    #learn.train_lda(dataset)\n",
    "    #learn.train_regression(dataset)\n",
    "        \n",
    "\n",
    "def rectification():\n",
    "    event_mapping = {'Rest': 100, 'Lift': 99, 'Squeeze': 98}\n",
    "    learn = PhysioLearn(\"Crawford_EMG_Model\", 1, \"emg\", event_mapping)\n",
    "    learn.readFile(\"data/crawford_EMG_Test.csv\")\n",
    "    learn.createEvents(\"data/crawford_events2.txt\")\n",
    "    \n",
    "    #Get Events\n",
    "    events = learn.getEvents()\n",
    "    \n",
    "    ## Plot all\n",
    "    '''\n",
    "    for x, event in enumerate(events):\n",
    "        start = int(events[x][0]/200)\n",
    "        data, times = learn.getEpoch(start, 5)\n",
    "        y = learn.rectify(data[0])\n",
    "        \n",
    "        #rectification (full-wave)\n",
    "        #data2 = [abs(x) for x in data[0]]\n",
    "        \n",
    "        learn.plotBasic(str(event[2]), y, times)  \n",
    "    '''\n",
    "    event = 4\n",
    "    start = int(events[event][0]/200)\n",
    "    data, times = learn.getEpoch(start, 5)\n",
    "    fs = 200\n",
    "    y = learn.rectify(data[0])\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "    ax1.plot(times, y)\n",
    "    \n",
    "    #filter\n",
    "    sos = signal.butter(4, 3, 'lowpass', fs=200, output='sos')\n",
    "    filtered = signal.sosfilt(sos, y)\n",
    "    ax2.plot(times, filtered)\n",
    "    test()\n",
    "        \n",
    "    '''\n",
    "    analytic_signal = hilbert(data[0])\n",
    "    amplitude_envelope = np.abs(analytic_signal)\n",
    "    instantaneous_phase = np.unwrap(np.angle(analytic_signal))\n",
    "    instantaneous_frequency = (np.diff(instantaneous_phase) /\n",
    "                           (2.0*np.pi) * fs)\n",
    "    '''\n",
    "    \n",
    "    #ax1.plot(t[1:], instantaneous_frequency)\n",
    "    \n",
    "    #print(analytic_signal)\n",
    "    '''\n",
    "    learn.plotBasic(f'Raw {event}', data[0], times)  \n",
    "    learn.plotBasic(f'analytic_signal {event}', analytic_signal, times)\n",
    "    learn.plotBasic(f'rectified signal {event}', y, times)\n",
    "    learn.plotBasic(f'instantaneous_frequency {event}', instantaneous_frequency, times[1:])\n",
    "    '''\n",
    "    #learn.getSignalEnvelope()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#main()\n",
    "rectification()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
